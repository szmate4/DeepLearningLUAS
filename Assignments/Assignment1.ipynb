{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d398a0e6",
   "metadata": {},
   "source": [
    "# Exercise project 1 (ANN regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f337122",
   "metadata": {},
   "source": [
    "### Step 0: Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809cb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723b9b71",
   "metadata": {},
   "source": [
    "### Step 1: Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a51394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"health_fitness_tracking_365days.csv\")\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0485d0e",
   "metadata": {},
   "source": [
    "### Step 2: Cleaning up dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fe2efc",
   "metadata": {},
   "source": [
    "### I check for missing values and inspect the data types to make sure my dataset is ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ec4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2033834",
   "metadata": {},
   "source": [
    "### I convert the 'gender' column into a numerical format using one-hot encoding, so I can use it as input for my neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58538a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "variables = ['gender']\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "one_hot_encoded = encoder.fit_transform(df[variables]).astype(int)\n",
    "df = pd.concat([df,one_hot_encoded],axis=1).drop(columns=variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10750583",
   "metadata": {},
   "source": [
    "#### I remove columns that I don't need for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c7c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns={\"date\",\"user_id\"})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8046b459",
   "metadata": {},
   "source": [
    "### Step 3: Train/test/validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679df966",
   "metadata": {},
   "source": [
    "#### I split my dataset into training, validation, and test sets so I can evaluate my model's performance on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=\"stress_level\")\n",
    "y=df[\"stress_level\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ce9e9a",
   "metadata": {},
   "source": [
    "## Step 4: Creating neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b8c81",
   "metadata": {},
   "source": [
    "#### Here, I build my deep learning model using Keras. I use several dense layers, batch normalization, and dropout to help with regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_amount = len(X.columns)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.BatchNormalization(input_shape=(variable_amount,)),\n",
    "        layers.Dense(18, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(l1=0.01)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(8, activation=\"relu\"),\n",
    "        layers.Dense(12, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30780de2",
   "metadata": {},
   "source": [
    "## Step 5: Fitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c302f04",
   "metadata": {},
   "source": [
    "#### I fit my model to the training data and plot the loss to see how the training process is going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=200, validation_data=(X_val, y_val))\n",
    "\n",
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71d3f3",
   "metadata": {},
   "source": [
    "#### I use the test set to evaluate how well my model predicts. I also visualize the results with a scatter plot to compare the true and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d727261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "sns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3642a",
   "metadata": {},
   "source": [
    "#### I plot the distribution of errors to see how close my model's predictions are to the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9552a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot((y_test - test_predictions))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b986b",
   "metadata": {},
   "source": [
    "## Step 6: Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8dbe65",
   "metadata": {},
   "source": [
    "#### I calculate and display different regression metrics to quantitatively measure how well my model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, test_predictions), 2))\n",
    "\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, test_predictions), 2))\n",
    "\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, test_predictions)), 2))\n",
    "\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, test_predictions), 2))\n",
    "\n",
    "print(\"\\nExplained variance score:\")\n",
    "print(round(metrics.explained_variance_score(y_test, test_predictions), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28aa74",
   "metadata": {},
   "source": [
    "### Step 7: Testing with given data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7aec2f",
   "metadata": {},
   "source": [
    "#### Finally, I use my trained model to predict the stress level for a new, hypothetical user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db294205",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_row = {\n",
    "    'user_id':0,\n",
    "    'age':17,\n",
    "    'gender':0,\n",
    "    'steps':30,\n",
    "    'heart_rate_avg':120,\n",
    "    'sleep_hours':3,\n",
    "    'calories_burned':1000,\n",
    "    'exercise_minutes':0,\n",
    "    'weight_kg':120,\n",
    "    'bmi':35\n",
    "}\n",
    "\n",
    "tester_row = pd.DataFrame([tester_row])\n",
    "result = model.predict(tester_row)[0]\n",
    "\n",
    "print(\"\\nEstimated stress level based on given data\")\n",
    "print(round(float(result[0]), 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
